= Protocol

Get():
First do a GetWithLease() against KVCache. If hit, then done.
If miss, then the server also returns a lease ID. The client then Get()s from
the back-end DB, and does a Put() using that lease ID into the cache.

Put() with update-tokens on back-end:
First do a GetUpdateToken() against backend.
Then, delete cache entry from all caches.
Finally, update the backend using the update token.

This requires the back-end to have update tokens.
An update token marks a key as uncacheable, so all future Gets() against the
back-end do not allow the KV pair to be put in a cache.
Update tokens can be arbitrarily revoked by the back-end, which can allow keys
to become cacheable again (if there are no outstanding update tokens), and this
also makes the update token invalid for a Put().

One approach to adding update tokens is to add an update server.
The update server keeps track of all the update tokens that have been issued and
not used/revoked. When one talks to the back-end, one now actually needs to talk
to the update server.

Put() with update-tokens in caches:
First do GetUpdateToken() against all cache servers.
Then, update the back-end.
Then, release GetUpdateToken()s.

If a cache server has loaned an update-token for a key that has not been
returned, then it cannot add that key to its cache.  This means that if a server
with an outstanding update-token disappears, then that key can never be cached.
There's no way to recover the update token, because we have no way of telling if
the update on the backend will happen.  E.g. maybe the client that wants to do
the update is really slow, and right after revoking the update token, some cache
server ends up with a cached copy of that key's old value. Then, the slow client
finally manages to do an update against the backend. That could cause some
caches to be get out-of-sync with the backend (i.e. this particular incorrect
approach wouldn't even give eventual consistency).

= UpdateToken-ifying a back-end DB.
Idea:
separate the update-token server from the backend
have an update-token proxy server, which makes RPCs against the real backend on
behalf of clients.
Update-token proxy also keeps state about outstanding update tokens.

It's seemingly possible to add update-tokens if we hold a server-wide lock on
the proxy server while doing the backend operations.
It seems possible that we could also hold only a per-key lock while doing these
backend operations, but it would be easy to do something that deadlocks.

Even a per-key lock seems a bit odd. Unclear yet whether it's fundamentally
necessary.
---
Say we first check while holding the lock that there are no outstanding
update-tokens on key `k`.
Then, release the lock.
Next we do `v := backend.Get(key)`.
We reply back to the client that `v` is cacheable.
Why is this safe?
two cases:
case 1.) no one tries updating that key in the time that we've let go of the
     lock, which reduces to the version in which we don't let go of the lock
     while doing the back-end Get().
case 2.) someone tries updating the key after we let go of the mutex.
     In this case, before the key gets updated in the backend, the client trying
     to do the update must delete() on all kvcache servers. This means the lease
     that the Get() client would try to use to update the cache will have been
     revoked.



= Misc
[ ] Maybe want one-sided RPCs (i.e. just messages) for the cache.
[ ] Rename Put() to Insert() in kvcache?
